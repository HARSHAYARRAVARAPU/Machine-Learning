{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Handwritten digits is classic dataset for classification task\n",
    "#Here we are applying various Machine learning models to classify the digits\n",
    "#\n",
    "#import packages\n",
    "import sklearn\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the digits dataset\n",
    "from sklearn.datasets import load_digits\n",
    "df = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29bd6633400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29bd66336d8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Representation of the digit on gray scale\n",
    "plt.gray()\n",
    "plt.matshow(df.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking out the features and targests from the dataset\n",
    "X= df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 14.  0.  0.  0.  0.  0.  0. 12.  9.  0.  0.  0.  0.  0.  0.\n",
      " 15.  3.  0.  0.  0.  0.  0.  1. 16.  0.  0.  0.  0.  0.  0.  1. 16.  2.\n",
      "  7.  4.  0.  0.  0.  3. 16. 16. 16. 16.  9.  0.  0.  0. 15. 15.  4. 10.\n",
      " 16.  0.  0.  0.  4. 14. 16. 12.  7.  0.]\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[67]) , print((y[67]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying train_test_split on the data set\n",
    "#Uncomment the following lines if u don't want to apply StratifiedKFold \n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train , X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test shapes which are divided in 80:20 ratio\n",
    "#print(X_train.shape, X_test.shape)\n",
    "#y_train ,y_test  = y_train.ravel(), y_test.ravel()\n",
    "#print((y_train.shape), (y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine learning models with the hyperparameters tuned \n",
    "lr = LogisticRegression(C=1.0, max_iter = 200, multi_class ='auto', solver ='liblinear')\n",
    "svm = SVC(C= 1.2 , gamma ='auto')\n",
    "rf = RandomForestClassifier(n_estimators = 25, criterion = 'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model function\n",
    "def model_fit(model, X, Y, x_test, y_test):\n",
    "    #Scaling the data as svm will prone to less\n",
    "    #accuracy if not done\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    #Fitting the model\n",
    "    model = model.fit(X,Y)\n",
    "    Y_pred = model.predict(x_test)\n",
    "    print(accuracy_score(y_test , Y_pred))\n",
    "    print(confusion_matrix(y_test , Y_pred))\n",
    "    return model, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy and Confusion matrix for Logistic Regression\n",
      "0.9318181818181818\n",
      "[[17  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 16  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 12  0  3  0  0  3  0]\n",
      " [ 0  0  0  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 16  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 17  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 16]]\n",
      "\n",
      "Accuracy and Confusion matrix for SVM\n",
      "0.9545454545454546\n",
      "[[17  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 18  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 13  0  3  0  0  2  0]\n",
      " [ 0  0  0  0 18  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 16  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 17  0]\n",
      " [ 0  0  0  0  0  1  0  0  1 16]]\n",
      "\n",
      "Accuracy and Confusion matrix for Random Forest\n",
      "0.9261363636363636\n",
      "[[17  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 18  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 11  0  3  0  0  4  0]\n",
      " [ 0  0  0  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 17  1  0  0  0]\n",
      " [ 0  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 17  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 16  0]\n",
      " [ 0  0  0  0  0  1  0  1  1 15]]\n"
     ]
    }
   ],
   "source": [
    "#Applying the StratifiedKFold on the data set so it gives better accuracy and consistent results \n",
    "#than train_test_split\n",
    "skf = StratifiedKFold(n_splits =10, random_state =42)\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "print(\"\\nAccuracy and Confusion matrix for Logistic Regression\")    \n",
    "lr , lr_pred = model_fit(lr, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nAccuracy and Confusion matrix for SVM\")   \n",
    "svm , svm_pred = model_fit(svm, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nAccuracy and Confusion matrix for Random Forest\")   \n",
    "rf , rf_pred= model_fit(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the Predicted and actual results into a csv file\n",
    "import pandas as pd\n",
    "new_data_frame = pd.DataFrame(lr_pred, y_test, columns =['Actual'])\n",
    "new_data_frame.to_csv(r\"C:\\Users\\yarravarapu.p\\Desktop\\all_models.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joblib_model.pkl']"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the model using Joblib we can also use pickle, json\n",
    "from sklearn.externals import joblib\n",
    "joblib_file = \"joblib_model.pkl\"\n",
    "#Dumping the model\n",
    "joblib.dump(rf, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the model\n",
    "model = joblib.load(r\"C:\\Users\\yarravarapu.p\\joblib_model.pkl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9147727272727273\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model on test data\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "#print(accuracy_score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
